{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow Model !\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "from cell import ConvLSTMCell\n",
    "import sys\n",
    "module_path = os.path.join(\"/home/pratik/work/dl/deepvideos/model/../\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from datasets.batch_generator import datasets\n",
    "slim = tf.contrib.slim\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.contrib.layers.python.layers import regularizers\n",
    "trunc_normal = lambda stddev: init_ops.truncated_normal_initializer(0.0, stddev)\n",
    "l2_val = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For looped RNN\n",
    "batch_size = 4\n",
    "timesteps = 32\n",
    "shape = [64, 64]  # Image shape\n",
    "kernel = [3, 3]\n",
    "channels = 3\n",
    "filters = [128, 128]  # 2 stacked conv lstm filters\n",
    "\n",
    "batch_size, time_step, H, W, C = [4, 32, 16, 16, 32]\n",
    "\n",
    "inp = tf.placeholder(tf.float32,(4, 64, 64, 3))\n",
    "with tf.variable_scope('conv_before_lstm'):\n",
    "    net = slim.conv2d(inp, 32, [3,3], scope='conv_1',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "    net = slim.conv2d(net, 64, [3,3], scope='conv_2',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "    net = slim.max_pool2d(net, [2,2], scope='pool_1')\n",
    "    net = slim.conv2d(net, 32, [3,3], scope='conv_3',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "    net = slim.max_pool2d(net, [2,2], scope='pool_2')\n",
    "    net = slim.conv2d(net, 32, [3,3], scope='conv_4',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "\n",
    "inp = tf.placeholder(tf.float32,(4, 16, 16, 128))\n",
    "with tf.variable_scope('deconv_after_lstm'):\n",
    "    net = slim.conv2d_transpose(inp, 64, [3,3], scope='deconv_1',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "    net = slim.conv2d_transpose(net, 32, [3,3], stride=2, scope='deconv_2',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "    net = slim.conv2d_transpose(net, 3, [3,3], stride=2, activation_fn=tf.tanh ,scope='deconv_3',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(inp):\n",
    "    with tf.variable_scope('conv_before_lstm',reuse=True):\n",
    "        net = slim.conv2d(inp, 32, [3,3], scope='conv_1',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        net = slim.conv2d(net, 64, [3,3], scope='conv_2',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        net = slim.max_pool2d(net, [2,2], scope='pool_1')\n",
    "        net = slim.conv2d(net, 32, [3,3], scope='conv_3',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        net = slim.max_pool2d(net, [2,2], scope='pool_2')\n",
    "        net = slim.conv2d(net, 32, [3,3], scope='conv_4',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv(inp):\n",
    "    with tf.variable_scope('deconv_after_lstm',reuse=True):\n",
    "        net = slim.conv2d_transpose(inp, 64, [3,3], scope='deconv_1',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        net = slim.conv2d_transpose(net, 32, [3,3], stride=2, scope='deconv_2',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        net = slim.conv2d_transpose(net, 3, [3,3], stride=2, activation_fn=tf.tanh ,scope='deconv_3',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [batch_size,] + [H,W] + [C], name=\"conv_lstm_inputs\")  # (batch_size, timestep, H, W, C)\n",
    "with tf.variable_scope('conv_lstm_model'):\n",
    "    cells = []\n",
    "    for i, each_filter in enumerate(filters):\n",
    "        cell = ConvLSTMCell([H,W], each_filter, kernel,reuse=tf.get_variable_scope().reuse)\n",
    "        cells.append(cell)\n",
    "\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)      \n",
    "    # states_series, current_state = tf.nn.dynamic_rnn(cell, lstm_reshape, dtype=lstm_reshape.dtype)\n",
    "    # current_state => Not used ... \n",
    "    # model_output = states_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/ConvLSTMCellZeroState/zeros:0' shape=(4, 16, 16, 128) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/ConvLSTMCellZeroState/zeros_1:0' shape=(4, 16, 16, 128) dtype=float32>),\n",
       " LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/ConvLSTMCellZeroState_1/zeros:0' shape=(4, 16, 16, 128) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/ConvLSTMCellZeroState_1/zeros_1:0' shape=(4, 16, 16, 128) dtype=float32>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_state = cell.zero_state(batch_size,dtype=inputs.dtype)\n",
    "zero_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'multi_rnn_cell/cell_1/cell_1/conv_lstm_cell/mul_5:0' shape=(4, 16, 16, 128) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_inp, h = cell(inputs,zero_state)\n",
    "next_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoved_layer = deconv(next_inp)\n",
    "op = conv_layer(decoved_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'deconv_after_lstm_1/deconv_3/Tanh:0' shape=(4, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoved_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = []\n",
    "for i in range(10):\n",
    "    o, h =  cell(op,h)\n",
    "    decoved_layer = deconv(o)\n",
    "    op = conv_layer(decoved_layer)\n",
    "    ans.append(decoved_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'deconv_after_lstm_2/deconv_3/Tanh:0' shape=(4, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_3/deconv_3/Tanh:0' shape=(4, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_4/deconv_3/Tanh:0' shape=(4, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_5/deconv_3/Tanh:0' shape=(4, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_6/deconv_3/Tanh:0' shape=(4, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_7/deconv_3/Tanh:0' shape=(4, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_8/deconv_3/Tanh:0' shape=(4, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_9/deconv_3/Tanh:0' shape=(4, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_10/deconv_3/Tanh:0' shape=(4, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_11/deconv_3/Tanh:0' shape=(4, 64, 64, 3) dtype=float32>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('done !', 0)\n",
      "('done !', 1)\n",
      "('done !', 2)\n",
      "('done !', 3)\n",
      "('done !', 4)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    i = 0\n",
    "    k = []\n",
    "    while i<5:\n",
    "        ans_np = sess.run(ans,feed_dict={inputs:np.random.rand(4,16,16,32)})\n",
    "        print (\"done !\",i)\n",
    "        i+=1\n",
    "        k.append(ans_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv_lstm_inputs:0' shape=(4, 16, 16, 32) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# condition in tensorflow ... \n",
    "# https://stackoverflow.com/questions/35833011/how-to-add-if-condition-in-a-tensorflow-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71747321,  0.95907478],\n",
       "       [ 0.6970599 ,  0.27284924],\n",
       "       [ 0.74154644,  0.03188344],\n",
       "       [ 0.62614959,  0.04581914]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "number_of_images_to_show = 4\n",
    "timesteps = 32\n",
    "shape = [64, 64]  # Image shape\n",
    "kernel = [3, 3]\n",
    "channels = 3\n",
    "filters = [256, 256]  # 2 stacked conv lstm filters\n",
    "images_summary_timesteps = [0, 4, 16, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a placeholder for videos.\n",
    "inputs = tf.placeholder(tf.float32, [batch_size, timesteps] + shape + [channels],\n",
    "                             name=\"conv_lstm_deconv_inputs\")  # (batch_size, timestep, H, W, C)\n",
    "outputs_exp = tf.placeholder(tf.float32, [batch_size, timesteps] + shape + [channels],\n",
    "                                  name=\"conv_lstm_deconv_outputs_exp\")  # (batch_size, timestep, H, W, C)\n",
    "teacher_force_sampling = tf.placeholder(tf.float32, [timesteps], name=\"teacher_force_sampling\")\n",
    "prob_select_teacher = tf.placeholder(tf.float32, shape=(), name=\"prob_select_teacher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv_lstm_deconv_inputs:0' shape=(2, 32, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv_lstm_deconv_outputs_exp:0' shape=(2, 32, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'teacher_force_sampling:0' shape=(32,) dtype=float32>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_force_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'prob_select_teacher:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_select_teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# model output\n",
    "model_output = None\n",
    "\n",
    "# loss\n",
    "l2_loss = None\n",
    "\n",
    "# optimizer\n",
    "optimizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(conv_input,reuse=None):\n",
    "    # conv before lstm\n",
    "    with tf.variable_scope('conv_before_lstm',reuse=reuse):\n",
    "        assert tf.get_variable_scope().reuse==reuse\n",
    "        net = slim.conv2d(conv_input, 32, [3, 3], scope='conv_1', weights_initializer=trunc_normal(0.01),\n",
    "                          weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        net = slim.conv2d(net, 64, [3, 3], stride=2, scope='conv_2', weights_initializer=trunc_normal(0.01),\n",
    "                          weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        net = slim.conv2d(net, 128, [3, 3], stride=2, scope='conv_3', weights_initializer=trunc_normal(0.01),\n",
    "                          weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='conv_4', weights_initializer=trunc_normal(0.01),\n",
    "                          weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv_layer(deconv_input,reuse=None):\n",
    "    with tf.variable_scope('deconv_after_lstm',reuse=reuse):\n",
    "        assert tf.get_variable_scope().reuse==reuse\n",
    "        net = slim.conv2d_transpose(deconv_input, 256, [3, 3], scope='deconv_4',\n",
    "                                    weights_initializer=trunc_normal(0.01),\n",
    "                                    weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        net = slim.conv2d_transpose(net, 128, [3, 3], scope='deconv_3', weights_initializer=trunc_normal(0.01),\n",
    "                                    weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        net = slim.conv2d_transpose(net, 64, [3, 3], stride=2, scope='deconv_2',\n",
    "                                    weights_initializer=trunc_normal(0.01),\n",
    "                                    weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        net = slim.conv2d_transpose(net, 32, [3, 3], stride=2, scope='deconv_1',\n",
    "                                    weights_initializer=trunc_normal(0.01),\n",
    "                                    weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        net = slim.conv2d_transpose(net, 3, [3, 3], activation_fn=tf.tanh, scope='deconv_0',\n",
    "                                    weights_initializer=trunc_normal(0.01),\n",
    "                                    weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_layer(H,W):\n",
    "    with tf.variable_scope('lstm_model'):\n",
    "        cells = []\n",
    "        for i, each_filter in enumerate(filters):\n",
    "            cell = ConvLSTMCell([H, W], each_filter, kernel,reuse=tf.get_variable_scope().reuse)\n",
    "            cells.append(cell)\n",
    "\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
    "        return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H, W, C = shape[0], shape[1], channels\n",
    "H, W, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Squeeze:0' shape=(2, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_frame = tf.slice(inputs,[0,0,0,0,0],[batch_size,1,H,W,C])\n",
    "first_frame = tf.squeeze(first_frame,[1])\n",
    "first_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv_before_lstm/conv_4/Relu:0' shape=(2, 16, 16, 256) dtype=float32>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_output = conv_layer(first_frame, reuse=None)\n",
    "conv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16, 16, 256)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CB, CH, CW, CC = conv_output.get_shape().as_list()\n",
    "CB, CH, CW, CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = lstm_layer(CH,CW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.rnn_cell_impl.MultiRNNCell at 0x7f8656fdf310>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/ConvLSTMCellZeroState/zeros:0' shape=(2, 16, 16, 256) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/ConvLSTMCellZeroState/zeros_1:0' shape=(2, 16, 16, 256) dtype=float32>),\n",
       " LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/ConvLSTMCellZeroState_1/zeros:0' shape=(2, 16, 16, 256) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/ConvLSTMCellZeroState_1/zeros_1:0' shape=(2, 16, 16, 256) dtype=float32>))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_state = cell.zero_state(batch_size,dtype=inputs.dtype)\n",
    "predications = []\n",
    "zeros_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deconv_input, h = cell(conv_output,zeros_state)\n",
    "deconv_output = deconv_layer(deconv_input,reuse=None)\n",
    "deconv_output\n",
    "predications.append(deconv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,timesteps):\n",
    "    select_sampling = tf.greater_equal(prob_select_teacher, tf.gather(teacher_force_sampling,i))\n",
    "    # Conv on actual t_timestep input\n",
    "    ith_frame = tf.slice(inputs,[0,i,0,0,0],[batch_size,1,H,W,C])\n",
    "    ith_frame = tf.squeeze(ith_frame,[1])\n",
    "    conv_output = conv_layer(ith_frame, reuse=True)\n",
    "    branch_1 = cell(conv_output, h)\n",
    "    # Conv on predicated t-1_timestep input\n",
    "    conv_output = conv_layer(deconv_output, reuse=True)\n",
    "    branch_2 = cell(conv_output, h)\n",
    "    deconv_input, h = tf.cond(select_sampling, lambda: branch_1, lambda: branch_2)\n",
    "    deconv_output = deconv_layer(deconv_input,reuse=True)\n",
    "    predications.append(deconv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'deconv_after_lstm/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_1/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_2/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_3/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_4/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_5/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_6/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_7/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_8/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_9/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_10/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_11/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_12/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_13/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_14/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_15/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_16/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_17/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_18/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_19/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_20/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_21/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_22/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_23/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_24/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_25/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_26/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_27/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_28/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_29/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_30/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_31/deconv_0/Tanh:0' shape=(2, 64, 64, 3) dtype=float32>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_output = tf.transpose(tf.stack(predications),perm=[1,0,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose:0' shape=(2, 32, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames_difference = tf.subtract(outputs_exp, model_output)\n",
    "batch_l2_loss = tf.nn.l2_loss(frames_difference)\n",
    "# divide by batch size ...\n",
    "l2_loss = tf.divide(batch_l2_loss, float(batch_size))\n",
    "l2_loss = l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truediv:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer().minimize(l2_loss)\n",
    "optimizer = train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/pratik/work/dl/deepvideos/notebooks/\"\n",
    "data_folder = os.path.join(file_path, \"../../data/\")\n",
    "log_dir_file_path = os.path.join(file_path, \"../../logs/\")\n",
    "model_save_file_path = os.path.join(file_path, \"../../checkpoint/\")\n",
    "output_video_save_file_path = os.path.join(file_path, \"../../output/\")\n",
    "iterations = \"iterations/\"\n",
    "best = \"best/\"\n",
    "checkpoint_iterations = 25\n",
    "best_model_iterations = 25\n",
    "best_l2_loss = float(\"inf\")\n",
    "heigth, width = 64, 64\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = datasets(batch_size=batch_size, heigth=heigth, width=width)\n",
    "for X_batch, y_batch, _ in data.train_next_batch():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 32, 64, 64, 3), (2, 32, 64, 64, 3))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sess.run([optimizer], feed_dict={\n",
    "                        inputs: X_batch, outputs_exp: y_batch, \n",
    "                        teacher_force_sampling: np.random.uniform(size=timesteps),\n",
    "                        prob_select_teacher : 0.5 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
