{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow Model !\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "from cell import ConvLSTMCell\n",
    "import sys\n",
    "module_path = os.path.join(\"/home/pratik/work/dl/deepvideos/model/../\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from datasets.batch_generator import datasets\n",
    "slim = tf.contrib.slim\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.contrib.layers.python.layers import regularizers\n",
    "trunc_normal = lambda stddev: init_ops.truncated_normal_initializer(0.0, stddev)\n",
    "l2_val = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For looped RNN\n",
    "batch_size = 4\n",
    "timesteps = 4\n",
    "conv_data_timesteps = timesteps * 2\n",
    "shape = [64, 64]  # Image shape\n",
    "H, W, C = 64, 64, 3\n",
    "kernel = [5, 5]\n",
    "channels = 3\n",
    "filters = [128, 128]  # 2 stacked conv lstm filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = tf.placeholder(tf.float32,(batch_size, conv_data_timesteps, H, W, C))\n",
    "inp_to_conv_layer = tf.reshape(inp,[-1,H,W,C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(inp,reuse):\n",
    "    with tf.variable_scope('conv_before_lstm',reuse=reuse):\n",
    "        net = slim.conv2d(inp, 128, [7,7], scope='conv_1',weights_initializer=trunc_normal(0.01))\n",
    "        print net\n",
    "        net = slim.conv2d(net, 256, [5,5], scope='conv_2',weights_initializer=trunc_normal(0.01))\n",
    "        print net\n",
    "        net = slim.conv2d(net, 512, [5,5], scope='conv_3',weights_initializer=trunc_normal(0.01))\n",
    "        print net\n",
    "        net = slim.conv2d(net, 256, [5,5], scope='conv_4',weights_initializer=trunc_normal(0.01))\n",
    "        print net\n",
    "        net = slim.conv2d(net, 128, [7,7], scope='conv_5',weights_initializer=trunc_normal(0.01))\n",
    "        print net\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv_layer(deconv_input,reuse=None):\n",
    "    with tf.variable_scope('deconv_after_lstm',reuse=reuse):\n",
    "        net = slim.conv2d_transpose(deconv_input, 128, [7, 7], scope='deconv_5',weights_initializer=trunc_normal(0.01))\n",
    "        print net\n",
    "        net = slim.conv2d_transpose(net, 256, [5, 5], scope='deconv_4', weights_initializer=trunc_normal(0.01))\n",
    "        print net\n",
    "        net = slim.conv2d_transpose(net, 512, [5, 5], scope='deconv_3',weights_initializer=trunc_normal(0.01))\n",
    "        print net\n",
    "        net = slim.conv2d_transpose(net, 256, [5, 5], scope='deconv_2',weights_initializer=trunc_normal(0.01))\n",
    "        print net\n",
    "        net = slim.conv2d_transpose(net, 128, [7, 7], scope='deconv_1',weights_initializer=trunc_normal(0.01))\n",
    "        print net\n",
    "        net = slim.conv2d_transpose(net, 3, [7, 7], activation_fn=tf.tanh, scope='deconv_0',weights_initializer=trunc_normal(0.01))\n",
    "        print net\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deinp = tf.placeholder(tf.float32,(batch_size, 8, H, W, 128))\n",
    "inp_to_deconv_layer = tf.reshape(deinp,[-1,64,64,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(32, 64, 64, 128) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_to_deconv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"deconv_after_lstm/deconv_5/Relu:0\", shape=(32, 64, 64, 128), dtype=float32)\n",
      "Tensor(\"deconv_after_lstm/deconv_4/Relu:0\", shape=(32, 64, 64, 256), dtype=float32)\n",
      "Tensor(\"deconv_after_lstm/deconv_3/Relu:0\", shape=(32, 64, 64, 512), dtype=float32)\n",
      "Tensor(\"deconv_after_lstm/deconv_2/Relu:0\", shape=(32, 64, 64, 256), dtype=float32)\n",
      "Tensor(\"deconv_after_lstm/deconv_1/Relu:0\", shape=(32, 64, 64, 128), dtype=float32)\n",
      "Tensor(\"deconv_after_lstm/deconv_0/Tanh:0\", shape=(32, 64, 64, 3), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'deconv_after_lstm/deconv_0/Tanh:0' shape=(32, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deconv_layer(inp_to_deconv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv_before_lstm/conv_1/Relu:0\", shape=(32, 64, 64, 128), dtype=float32)\n",
      "Tensor(\"conv_before_lstm/conv_2/Relu:0\", shape=(32, 64, 64, 256), dtype=float32)\n",
      "Tensor(\"conv_before_lstm/conv_3/Relu:0\", shape=(32, 64, 64, 512), dtype=float32)\n",
      "Tensor(\"conv_before_lstm/conv_4/Relu:0\", shape=(32, 64, 64, 256), dtype=float32)\n",
      "Tensor(\"conv_before_lstm/conv_5/Relu:0\", shape=(32, 64, 64, 128), dtype=float32)\n",
      "(32, 64, 64, 128)\n",
      "Tensor(\"Reshape_2:0\", shape=(4, 8, 64, 64, 128), dtype=float32)\n",
      "Tensor(\"Slice:0\", shape=(4, 4, 64, 64, 128), dtype=float32)\n",
      "Tensor(\"Slice_1:0\", shape=(4, 4, 64, 64, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output_of_conv_layer = conv_layer(inp_to_conv_layer,None)\n",
    "cB, cH, cW, cC = output_of_conv_layer.get_shape().as_list()\n",
    "print (cB,cH,cW,cC)\n",
    "inp_time_based = tf.reshape(output_of_conv_layer, [-1,conv_data_timesteps, cH, cW, cC])\n",
    "print (inp_time_based)\n",
    "encoder_input = tf.slice(inp_time_based,[0,0,0,0,0],[batch_size,timesteps,cH,cW,cC])\n",
    "print (encoder_input)\n",
    "decoder_input = tf.slice(inp_time_based,[0,timesteps,0,0,0],[batch_size,timesteps,cH,cW,cC])\n",
    "print (decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernels = [[3,3],[5, 5]]\n",
    "H, W = 64, 64\n",
    "with tf.variable_scope('enc_conv_lstm_model'):\n",
    "    cells = []\n",
    "    for i, (each_filter,each_kernel) in enumerate(zip(filters,kernels)):\n",
    "        cell = ConvLSTMCell([H,W], each_filter, each_kernel,reuse=tf.get_variable_scope().reuse)\n",
    "        cells.append(cell)\n",
    "\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.rnn_cell_impl.MultiRNNCell at 0x7fe46d43e790>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/ConvLSTMCellZeroState/zeros:0' shape=(4, 64, 64, 128) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/ConvLSTMCellZeroState/zeros_1:0' shape=(4, 64, 64, 128) dtype=float32>),\n",
       " LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/ConvLSTMCellZeroState_1/zeros:0' shape=(4, 64, 64, 128) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/ConvLSTMCellZeroState_1/zeros_1:0' shape=(4, 64, 64, 128) dtype=float32>))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_state = cell.zero_state(batch_size,dtype=tf.float32)\n",
    "zero_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_output, encoder_state = tf.nn.dynamic_rnn(cell,inputs=encoder_input,initial_state=zero_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Slice:0' shape=(4, 4, 64, 64, 128) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/transpose:0' shape=(4, 4, 64, 64, 128) dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(4, 64, 64, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(4, 64, 64, 128) dtype=float32>),\n",
       " LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_4:0' shape=(4, 64, 64, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_5:0' shape=(4, 64, 64, 128) dtype=float32>))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 64, 64, 128]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernels = [[3,3],[5, 5]]\n",
    "H, W = 64, 64\n",
    "with tf.variable_scope('dec_conv_lstm_model'):\n",
    "    cells = []\n",
    "    for i, (each_filter,each_kernel) in enumerate(zip(filters,kernels)):\n",
    "        cell = ConvLSTMCell([H,W], each_filter, each_kernel,reuse=tf.get_variable_scope().reuse)\n",
    "        cells.append(cell)\n",
    "\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "number_of_images_to_show = 4\n",
    "assert number_of_images_to_show <= batch_size\n",
    "shape = [64, 64]  # Image shape\n",
    "H, W = shape\n",
    "kernels = [[3, 3],[5, 5]]\n",
    "channels = C = 3\n",
    "filters = [128, 128]  # 2 stacked conv lstm filters\n",
    "enc_timesteps = 8 - 1\n",
    "dec_timesteps = 8\n",
    "timesteps = enc_timesteps + dec_timesteps\n",
    "images_summary_timesteps = [0, 2, 5, 7]\n",
    "\n",
    "# Create a placeholder for videos.\n",
    "inputs = tf.placeholder(tf.float32, [batch_size, timesteps] + shape + [channels],\n",
    "                             name=\"seq2seq_inputs\")  # (batch_size, timestep, H, W, C)\n",
    "outputs_exp = tf.placeholder(tf.float32, [batch_size, dec_timesteps] + shape + [channels],\n",
    "                                  name=\"seq2seq_outputs_exp\")  # (batch_size, timestep, H, W, C)\n",
    "teacher_force_sampling = tf.placeholder(tf.float32, [dec_timesteps], name=\"teacher_force_sampling\")\n",
    "prob_select_teacher = tf.placeholder(tf.float32, shape=(), name=\"prob_select_teacher\")\n",
    "\n",
    "# model output\n",
    "model_output = None\n",
    "\n",
    "# loss\n",
    "l2_loss = None\n",
    "\n",
    "# optimizer\n",
    "optimizer = None\n",
    "\n",
    "reuse_conv = None\n",
    "reuse_deconv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(conv_input):\n",
    "        # conv before lstm\n",
    "        with tf.variable_scope('conv_before_lstm',reuse=True):\n",
    "            net = slim.conv2d(conv_input, 128, [7,7], scope='conv_1',weights_initializer=trunc_normal(0.01))\n",
    "            net = slim.conv2d(net, 256, [5,5], scope='conv_2',weights_initializer=trunc_normal(0.01))\n",
    "            net = slim.conv2d(net, 512, [5,5], scope='conv_3',weights_initializer=trunc_normal(0.01))\n",
    "            net = slim.conv2d(net, 256, [5,5], scope='conv_4',weights_initializer=trunc_normal(0.01))\n",
    "            net = slim.conv2d(net, 128, [7,7], scope='conv_5',weights_initializer=trunc_normal(0.01))\n",
    "            reuse_conv = True\n",
    "            return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv_layer(deconv_input):\n",
    "        with tf.variable_scope('deconv_after_lstm',reuse=True):\n",
    "            net = slim.conv2d_transpose(deconv_input, 128, [7, 7], scope='deconv_5',weights_initializer=trunc_normal(0.01))\n",
    "            net = slim.conv2d_transpose(net, 256, [5, 5], scope='deconv_4', weights_initializer=trunc_normal(0.01))\n",
    "            net = slim.conv2d_transpose(net, 512, [5, 5], scope='deconv_3',weights_initializer=trunc_normal(0.01))\n",
    "            net = slim.conv2d_transpose(net, 256, [5, 5], scope='deconv_2',weights_initializer=trunc_normal(0.01))\n",
    "            net = slim.conv2d_transpose(net, 128, [7, 7], scope='deconv_1',weights_initializer=trunc_normal(0.01))\n",
    "            net = slim.conv2d_transpose(net, 3, [7, 7], activation_fn=tf.tanh, scope='deconv_0',weights_initializer=trunc_normal(0.01))\n",
    "            reuse_deconv = True\n",
    "            return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enc_lstm_layer(H,W):\n",
    "        with tf.variable_scope('enc_lstm_model'):\n",
    "            cells = []\n",
    "            for i, (each_filter, each_kernel) in enumerate(zip(filters,kernels)):\n",
    "                cell = ConvLSTMCell([H, W], each_filter, each_kernel,reuse=tf.get_variable_scope().reuse)\n",
    "                cells.append(cell)\n",
    "\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
    "            return cell\n",
    "\n",
    "def dec_lstm_layer(H,W):\n",
    "        with tf.variable_scope('dec_lstm_model'):\n",
    "            cells = []\n",
    "            for i, (each_filter, each_kernel) in enumerate(zip(filters,kernels)):\n",
    "                cell = ConvLSTMCell([H, W], each_filter, each_kernel,reuse=tf.get_variable_scope().reuse)\n",
    "                cells.append(cell)\n",
    "\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
    "            return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H, W, C = shape[0], shape[1], channels\n",
    "input_conv_layer = tf.reshape(inputs, [-1,H,W,C])\n",
    "output_conv_layer = conv_layer(input_conv_layer)\n",
    "_, H, W, C = output_conv_layer.get_shape().as_list()\n",
    "lstm_shaped_input = tf.reshape(output_conv_layer, [-1,timesteps,H,W,C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(240, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv_before_lstm/conv_5/Relu:0' shape=(240, 64, 64, 128) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(16, 15, 64, 64, 128) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_shaped_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slice first part to feed to encoder and second to decoder\n",
    "encoder_inp = tf.slice(lstm_shaped_input,[0,0,0,0,0],[batch_size,enc_timesteps,H,W,C])\n",
    "decoder_inp = tf.slice(lstm_shaped_input,[0,enc_timesteps,0,0,0],[batch_size,dec_timesteps,H,W,C])\n",
    "\n",
    "# dynamic rnn as encoder\n",
    "encoder_cell = enc_lstm_layer(H,W)\n",
    "zero_state = encoder_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "encoder_output, encoder_final_state = tf.nn.dynamic_rnn(encoder_cell,inputs=encoder_inp,initial_state=zero_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(16, 64, 64, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(16, 64, 64, 128) dtype=float32>),\n",
       " LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_4:0' shape=(16, 64, 64, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_5:0' shape=(16, 64, 64, 128) dtype=float32>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/transpose:0' shape=(16, 7, 64, 64, 128) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decoder cell \n",
    "decoder_cell = dec_lstm_layer(H,W)\n",
    "state = encoder_final_state\n",
    "input_for_first_time = tf.slice(decoder_inp, [0,0,0,0,0], [batch_size,1,H,W,C])\n",
    "input_for_first_time = tf.squeeze(input_for_first_time,[1])\n",
    "input_deconv, state = decoder_cell(input_for_first_time,state)\n",
    "predications = []\n",
    "deconv_output = deconv_layer(input_deconv)\n",
    "predications.append(deconv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Squeeze:0' shape=(16, 64, 64, 128) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_for_first_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'multi_rnn_cell/cell_1/cell_1/conv_lstm_cell/mul_5:0' shape=(16, 64, 64, 128) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_deconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'deconv_after_lstm/deconv_0/Tanh:0' shape=(16, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deconv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,dec_timesteps):\n",
    "    select_sampling = tf.greater_equal(prob_select_teacher, tf.gather(teacher_force_sampling,i))\n",
    "    # Conv on actual t_timestep input\n",
    "    ith_frame = tf.slice(decoder_inp,[0,i,0,0,0],[batch_size,1,64,64,3])\n",
    "    ith_frame = tf.squeeze(ith_frame,[1])\n",
    "    conv_output = conv_layer(ith_frame)\n",
    "    branch_1 = decoder_cell(conv_output, state)\n",
    "    # Conv on predicated t-1_timestep input\n",
    "    conv_output = conv_layer(deconv_output)\n",
    "    branch_2 = decoder_cell(conv_output, state)\n",
    "\n",
    "    deconv_input, state = tf.cond(select_sampling, lambda: branch_1, lambda: branch_2)\n",
    "    deconv_output = deconv_layer(deconv_input)\n",
    "    predications.append(deconv_output)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'deconv_after_lstm/deconv_0/Tanh:0' shape=(16, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_1/deconv_0/Tanh:0' shape=(16, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_2/deconv_0/Tanh:0' shape=(16, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_3/deconv_0/Tanh:0' shape=(16, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_4/deconv_0/Tanh:0' shape=(16, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_5/deconv_0/Tanh:0' shape=(16, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_6/deconv_0/Tanh:0' shape=(16, 64, 64, 3) dtype=float32>,\n",
       " <tf.Tensor 'deconv_after_lstm_7/deconv_0/Tanh:0' shape=(16, 64, 64, 3) dtype=float32>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_output = tf.transpose(tf.stack(predications),perm=[1,0,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose_1:0' shape=(16, 8, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'seq2seq_outputs_exp:0' shape=(16, 8, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_loss(generated_frames, expected_frames):\n",
    "    losses = []\n",
    "    for each_scale_gen_frames, each_scale_exp_frames in zip(generated_frames, expected_frames):\n",
    "        losses.append(tf.nn.l2_loss(tf.subtract(each_scale_gen_frames, each_scale_exp_frames)))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.stack(losses))\n",
    "    return loss\n",
    "\n",
    "def gdl_loss(generated_frames, expected_frames, alpha=2):\n",
    "    \"\"\"\n",
    "    difference with side pixel and below pixel\n",
    "    \"\"\"\n",
    "    scale_losses = []\n",
    "    for i in xrange(len(generated_frames)):\n",
    "        # create filters [-1, 1] and [[1],[-1]] for diffing to the left and down respectively.\n",
    "        pos = tf.constant(np.identity(3), dtype=tf.float32)\n",
    "        neg = -1 * pos\n",
    "        filter_x = tf.expand_dims(tf.stack([neg, pos]), 0)  # [-1, 1]\n",
    "        filter_y = tf.stack([tf.expand_dims(pos, 0), tf.expand_dims(neg, 0)])  # [[1],[-1]]\n",
    "        strides = [1, 1, 1, 1]  # stride of (1, 1)\n",
    "        padding = 'SAME'\n",
    "\n",
    "        gen_dx = tf.abs(tf.nn.conv2d(generated_frames[i], filter_x, strides, padding=padding))\n",
    "        gen_dy = tf.abs(tf.nn.conv2d(generated_frames[i], filter_y, strides, padding=padding))\n",
    "        gt_dx = tf.abs(tf.nn.conv2d(expected_frames[i], filter_x, strides, padding=padding))\n",
    "        gt_dy = tf.abs(tf.nn.conv2d(expected_frames[i], filter_y, strides, padding=padding))\n",
    "\n",
    "        grad_diff_x = tf.abs(gt_dx - gen_dx)\n",
    "        grad_diff_y = tf.abs(gt_dy - gen_dy)\n",
    "\n",
    "        scale_losses.append(tf.reduce_sum((grad_diff_x ** alpha + grad_diff_y ** alpha)))\n",
    "\n",
    "    # condense into one tensor and avg\n",
    "    return tf.reduce_mean(tf.stack(scale_losses))\n",
    "\n",
    "def total_loss(generated_frames, expected_frames, lambda_gdl=1.0, lambda_l2=1.0):\n",
    "      B, T, H, W, C = generated_frames.get_shape().as_list()\n",
    "      B1, T1, H1, W1, C1 = expected_frames.get_shape().as_list()\n",
    "      assert (B, T, H, W, C)==(B1, T1, H1, W1, C1),\"shape should be equal of gen and exp frames !\"\n",
    "      each_step_gen_frames = []\n",
    "      each_step_exp_frames = []\n",
    "      for each_i in range(T):\n",
    "            input_for_gen = tf.slice(generated_frames, [0,each_i,0,0,0], [B,1,H,W,C])\n",
    "            input_for_gen = tf.squeeze(input_for_gen,[1])\n",
    "            each_step_gen_frames.append(input_for_gen)\n",
    "            \n",
    "            input_for_exp = tf.slice(expected_frames, [0,each_i,0,0,0], [B,1,H,W,C])\n",
    "            input_for_exp = tf.squeeze(input_for_exp,[1])\n",
    "            each_step_exp_frames.append(input_for_exp)\n",
    "\n",
    "      total_loss_cal = (lambda_gdl * gdl_loss(each_step_gen_frames, each_step_exp_frames) + \n",
    "                     lambda_l2 * l2_loss(each_step_gen_frames, each_step_exp_frames))\n",
    "      return total_loss_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Squeeze_25:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "Tensor(\"Squeeze_26:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "======\n",
      "Tensor(\"Squeeze_27:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "Tensor(\"Squeeze_28:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "======\n",
      "Tensor(\"Squeeze_29:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "Tensor(\"Squeeze_30:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "======\n",
      "Tensor(\"Squeeze_31:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "Tensor(\"Squeeze_32:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "======\n",
      "Tensor(\"Squeeze_33:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "Tensor(\"Squeeze_34:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "======\n",
      "Tensor(\"Squeeze_35:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "Tensor(\"Squeeze_36:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "======\n",
      "Tensor(\"Squeeze_37:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "Tensor(\"Squeeze_38:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "======\n",
      "Tensor(\"Squeeze_39:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "Tensor(\"Squeeze_40:0\", shape=(16, 64, 64, 3), dtype=float32)\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "l = total_loss(model_output,outputs_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Slice:0' shape=(16, 7, 64, 64, 128) dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Slice_1:0' shape=(16, 8, 64, 64, 128) dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(1*15*64*64*3).reshape((1,15,64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = tf.constant(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = tf.slice(p,[0,7,0,0,0],[1,8,64,64,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Slice_12:0' shape=(1, 8, 64, 64, 3) dtype=int64>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8, 64, 64, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ReModeling ... Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "number_of_images_to_show = 4\n",
    "assert number_of_images_to_show <= batch_size\n",
    "shape = [64, 64]  # Image shape\n",
    "H, W = shape\n",
    "kernels = [[3, 3],[5, 5]]\n",
    "channels = C = 3\n",
    "enc_timesteps = 4 - 1\n",
    "dec_timesteps = 4\n",
    "timesteps = enc_timesteps + dec_timesteps\n",
    "images_summary_timesteps = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a placeholder for videos.\n",
    "inputs = tf.placeholder(tf.float32, [batch_size, timesteps] + shape + [channels],\n",
    "                             name=\"seq2seq_inputs\")  # (batch_size, timestep, H, W, C)\n",
    "outputs_exp = tf.placeholder(tf.float32, [batch_size, dec_timesteps] + shape + [channels],\n",
    "                                  name=\"seq2seq_outputs_exp\")  # (batch_size, timestep, H, W, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'seq2seq_inputs:0' shape=(16, 7, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'seq2seq_outputs_exp:0' shape=(16, 4, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(conv_input,reuse=None):\n",
    "        # conv before lstm\n",
    "        with tf.variable_scope('conv_before_lstm',reuse=reuse):\n",
    "            net = slim.conv2d(conv_input, 32, [3, 3], scope='conv_1', weights_initializer=trunc_normal(0.01),\n",
    "                              weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "            print net\n",
    "            net = slim.conv2d(net, 64, [3, 3], scope='conv_2', weights_initializer=trunc_normal(0.01),\n",
    "                              weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "            print net\n",
    "            net = slim.conv2d(net, 128, [3, 3], stride=2, scope='conv_3', weights_initializer=trunc_normal(0.01),\n",
    "                              weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "            print net\n",
    "            net = slim.conv2d(net, 256, [3, 3], stride=2, scope='conv_4', weights_initializer=trunc_normal(0.01),\n",
    "                              weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "            print net\n",
    "            return net\n",
    "        \n",
    "        \n",
    "def deconv_layer(deconv_input,reuse=None):\n",
    "        with tf.variable_scope('deconv_after_lstm',reuse=reuse):\n",
    "            net = slim.conv2d_transpose(deconv_input, 256, [3, 3], scope='deconv_4',\n",
    "                                        weights_initializer=trunc_normal(0.01),\n",
    "                                        weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "            print net\n",
    "            net = slim.conv2d_transpose(net, 128, [3, 3], stride=2, scope='deconv_3', weights_initializer=trunc_normal(0.01),\n",
    "                                        weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "            print net\n",
    "            net = slim.conv2d_transpose(net, 64, [3, 3], stride=2, scope='deconv_2',\n",
    "                                        weights_initializer=trunc_normal(0.01),\n",
    "                                        weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "            print net\n",
    "            net = slim.conv2d_transpose(net, 32, [3, 3], scope='deconv_1',\n",
    "                                        weights_initializer=trunc_normal(0.01),\n",
    "                                        weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "            print net\n",
    "            net = slim.conv2d_transpose(net, 3, [3, 3], activation_fn=tf.tanh, scope='deconv_0',\n",
    "                                        weights_initializer=trunc_normal(0.01),\n",
    "                                        weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "            print net\n",
    "            return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 7, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "B, T, H, W, C = inputs.get_shape().as_list()\n",
    "print (B, T, H, W, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reshaped_inputs_for_conv = tf.reshape(inputs, [-1,H,W,C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(112, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_inputs_for_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv_before_lstm/conv_1/Relu:0\", shape=(112, 64, 64, 32), dtype=float32)\n",
      "Tensor(\"conv_before_lstm/conv_2/Relu:0\", shape=(112, 64, 64, 64), dtype=float32)\n",
      "Tensor(\"conv_before_lstm/conv_3/Relu:0\", shape=(112, 32, 32, 128), dtype=float32)\n",
      "Tensor(\"conv_before_lstm/conv_4/Relu:0\", shape=(112, 16, 16, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conved_output = conv_layer(reshaped_inputs_for_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_lstm_encoder(H,W,filter_size,kernel,encoder_input):\n",
    "    with tf.variable_scope('enc_lstm_model'):\n",
    "        encoder_cell = ConvLSTMCell([H,W], filter_size, kernel,reuse=tf.get_variable_scope().reuse)\n",
    "        zero_state = encoder_cell.zero_state(batch_size,dtype=tf.float32)\n",
    "        _, encoded_state = tf.nn.dynamic_rnn(cell=encoder_cell, inputs=encoder_input, initial_state=zero_state)\n",
    "        return encoded_state\n",
    "    \n",
    "def conv_lstm_decoder(H,W,filter_size,kernel,decoder_input,enc_final_state):\n",
    "    with tf.variable_scope('dec_lstm_model'):\n",
    "        decoder_cell = ConvLSTMCell([H,W], filter_size, kernel,reuse=tf.get_variable_scope().reuse)\n",
    "        decoder_outputs, _ = tf.nn.dynamic_rnn(cell=decoder_cell, inputs=decoder_input, initial_state=enc_final_state)\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 16, 16, 256)\n",
      "Tensor(\"Reshape_1:0\", shape=(16, 7, 16, 16, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "_, H, W, C = conved_output.get_shape().as_list()\n",
    "print (_, H, W, C)\n",
    "lstm_input_reshape = tf.reshape(conved_output, [B,T,H,W,C])\n",
    "print lstm_input_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Slice:0\", shape=(16, 3, 16, 16, 256), dtype=float32)\n",
      "Tensor(\"Slice_1:0\", shape=(16, 4, 16, 16, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "B, T, H, W, C = lstm_input_reshape.get_shape().as_list()\n",
    "\n",
    "# split conv input into two parts \n",
    "encoder_input_from_conv = tf.slice(lstm_input_reshape,[0,0,0,0,0],[B,enc_timesteps,H,W,C])\n",
    "decoder_input_from_conv = tf.slice(lstm_input_reshape,[0,enc_timesteps,0,0,0],[B,dec_timesteps,H,W,C])\n",
    "\n",
    "print encoder_input_from_conv\n",
    "print decoder_input_from_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMStateTuple(c=<tf.Tensor 'enc_lstm_model/rnn/while/Exit_2:0' shape=(16, 16, 16, 256) dtype=float32>, h=<tf.Tensor 'enc_lstm_model/rnn/while/Exit_3:0' shape=(16, 16, 16, 256) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "filter_size = C\n",
    "kernel_size = [3,3]\n",
    "encoded_state = conv_lstm_encoder(H,W,filter_size,kernel_size,encoder_input_from_conv)\n",
    "print encoded_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_output = conv_lstm_decoder(H,W,filter_size,kernel_size,decoder_input_from_conv,encoded_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dec_lstm_model/rnn/transpose:0' shape=(16, 4, 16, 16, 256) dtype=float32>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"deconv_after_lstm/deconv_4/Relu:0\", shape=(64, 16, 16, 256), dtype=float32)\n",
      "Tensor(\"deconv_after_lstm/deconv_3/Relu:0\", shape=(64, 32, 32, 128), dtype=float32)\n",
      "Tensor(\"deconv_after_lstm/deconv_2/Relu:0\", shape=(64, 64, 64, 64), dtype=float32)\n",
      "Tensor(\"deconv_after_lstm/deconv_1/Relu:0\", shape=(64, 64, 64, 32), dtype=float32)\n",
      "Tensor(\"deconv_after_lstm/deconv_0/Tanh:0\", shape=(64, 64, 64, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# pass through deconv layer\n",
    "B, T, H, W, C = decoder_output.get_shape().as_list()\n",
    "deconv_layer_input = tf.reshape(decoder_output,[-1,H, W, C])\n",
    "predication = deconv_layer(deconv_layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 4, 16, 16, 256)\n",
      "(16, 4, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print (B, T, H, W, C)\n",
    "_, H, W, C = predication.get_shape().as_list()\n",
    "print (B, T, H, W, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_5:0\", shape=(16, 4, 64, 64, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model_output = tf.reshape(predication,[B,T,H,W,C])\n",
    "print model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_loss(generated_frames, expected_frames):\n",
    "    losses = []\n",
    "    for each_scale_gen_frames, each_scale_exp_frames in zip(generated_frames, expected_frames):\n",
    "        losses.append(tf.nn.l2_loss(tf.subtract(each_scale_gen_frames, each_scale_exp_frames)))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.stack(losses))\n",
    "    return loss\n",
    "\n",
    "def gdl_loss(generated_frames, expected_frames, alpha=2):\n",
    "    \"\"\"\n",
    "    difference with side pixel and below pixel\n",
    "    \"\"\"\n",
    "    scale_losses = []\n",
    "    for i in xrange(len(generated_frames)):\n",
    "        # create filters [-1, 1] and [[1],[-1]] for diffing to the left and down respectively.\n",
    "        pos = tf.constant(np.identity(3), dtype=tf.float32)\n",
    "        neg = -1 * pos\n",
    "        filter_x = tf.expand_dims(tf.stack([neg, pos]), 0)  # [-1, 1]\n",
    "        filter_y = tf.stack([tf.expand_dims(pos, 0), tf.expand_dims(neg, 0)])  # [[1],[-1]]\n",
    "        strides = [1, 1, 1, 1]  # stride of (1, 1)\n",
    "        padding = 'SAME'\n",
    "\n",
    "        gen_dx = tf.abs(tf.nn.conv2d(generated_frames[i], filter_x, strides, padding=padding))\n",
    "        gen_dy = tf.abs(tf.nn.conv2d(generated_frames[i], filter_y, strides, padding=padding))\n",
    "        gt_dx = tf.abs(tf.nn.conv2d(expected_frames[i], filter_x, strides, padding=padding))\n",
    "        gt_dy = tf.abs(tf.nn.conv2d(expected_frames[i], filter_y, strides, padding=padding))\n",
    "\n",
    "        grad_diff_x = tf.abs(gt_dx - gen_dx)\n",
    "        grad_diff_y = tf.abs(gt_dy - gen_dy)\n",
    "\n",
    "        scale_losses.append(tf.reduce_sum((grad_diff_x ** alpha + grad_diff_y ** alpha)))\n",
    "\n",
    "    # condense into one tensor and avg\n",
    "    return tf.reduce_mean(tf.stack(scale_losses))\n",
    "\n",
    "def total_loss(generated_frames, expected_frames, lambda_gdl=1.0, lambda_l2=1.0):\n",
    "      B, T, H, W, C = generated_frames.get_shape().as_list()\n",
    "      B1, T1, H1, W1, C1 = expected_frames.get_shape().as_list()\n",
    "      assert (B, T, H, W, C)==(B1, T1, H1, W1, C1),\"shape should be equal of gen and exp frames !\"\n",
    "      each_step_gen_frames = []\n",
    "      each_step_exp_frames = []\n",
    "      for each_i in range(T):\n",
    "            input_for_gen = tf.slice(generated_frames, [0,each_i,0,0,0], [B,1,H,W,C])\n",
    "            input_for_gen = tf.squeeze(input_for_gen,[1])\n",
    "            each_step_gen_frames.append(input_for_gen)\n",
    "            \n",
    "            input_for_exp = tf.slice(expected_frames, [0,each_i,0,0,0], [B,1,H,W,C])\n",
    "            input_for_exp = tf.squeeze(input_for_exp,[1])\n",
    "            each_step_exp_frames.append(input_for_exp)\n",
    "\n",
    "      total_loss_cal = (lambda_gdl * gdl_loss(each_step_gen_frames, each_step_exp_frames) + \n",
    "                     lambda_l2 * l2_loss(each_step_gen_frames, each_step_exp_frames))\n",
    "      return total_loss_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = total_loss(model_output,outputs_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_4:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "[4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "a = range(8)\n",
    "print a[:7]\n",
    "print a[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
