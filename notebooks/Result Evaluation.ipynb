{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/anaconda2/lib/python2.7/site-packages/skvideo/__init__.py:356: UserWarning: avconv/avprobe not found in path: \n",
      "  warnings.warn(\"avconv/avprobe not found in path: \" + str(path), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import skvideo.io\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.contrib.layers.python.layers import regularizers\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "tf.reset_default_graph()\n",
    "trunc_normal = lambda stddev: init_ops.truncated_normal_initializer(0.0, stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#====================  COPIED CODE ===============================================\n",
    "#\n",
    "#  TENSORBOARD VISUALIZATION FOR SHARPNESS AND (Peak Signal to Noise Ratio){PSNR}\n",
    "#=================================================================================\n",
    "def log10(t):\n",
    "    \"\"\"\n",
    "    Calculates the base-10 log of each element in t.\n",
    "    @param t: The tensor from which to calculate the base-10 log.\n",
    "    @return: A tensor with the base-10 log of each element in t.\n",
    "    \"\"\"\n",
    "    numerator = tf.log(t)\n",
    "    denominator = tf.log(tf.constant(10, dtype=numerator.dtype))\n",
    "    return numerator / denominator\n",
    "    \n",
    "def psnr_error(gen_frames, gt_frames):\n",
    "    \"\"\"\n",
    "    Computes the Peak Signal to Noise Ratio error between the generated images and the ground\n",
    "    truth images.\n",
    "    @param gen_frames: A tensor of shape [batch_size, height, width, 3]. The frames generated by the\n",
    "                       generator model.\n",
    "    @param gt_frames: A tensor of shape [batch_size, height, width, 3]. The ground-truth frames for\n",
    "                      each frame in gen_frames.\n",
    "    @return: A scalar tensor. The mean Peak Signal to Noise Ratio error over each frame in the\n",
    "             batch.\n",
    "    \"\"\"\n",
    "    shape = tf.shape(gen_frames)\n",
    "    num_pixels = tf.to_float(shape[1] * shape[2] * shape[3])\n",
    "    square_diff = tf.square(gt_frames - gen_frames)\n",
    "\n",
    "    batch_errors = 10 * log10(1 / ((1 / num_pixels) * tf.reduce_sum(square_diff, [1, 2, 3])))\n",
    "    return tf.reduce_mean(batch_errors)\n",
    "\n",
    "def sharp_diff_error(gen_frames, gt_frames):\n",
    "    \"\"\"\n",
    "    Computes the Sharpness Difference error between the generated images and the ground truth\n",
    "    images.\n",
    "    @param gen_frames: A tensor of shape [batch_size, height, width, 3]. The frames generated by the\n",
    "                       generator model.\n",
    "    @param gt_frames: A tensor of shape [batch_size, height, width, 3]. The ground-truth frames for\n",
    "                      each frame in gen_frames.\n",
    "    @return: A scalar tensor. The Sharpness Difference error over each frame in the batch.\n",
    "    \"\"\"\n",
    "    shape = tf.shape(gen_frames)\n",
    "    num_pixels = tf.to_float(shape[1] * shape[2] * shape[3])\n",
    "\n",
    "    # gradient difference\n",
    "    # create filters [-1, 1] and [[1],[-1]] for diffing to the left and down respectively.\n",
    "    # TODO: Could this be simplified with one filter [[-1, 2], [0, -1]]?\n",
    "    pos = tf.constant(np.identity(3), dtype=tf.float32)\n",
    "    neg = -1 * pos\n",
    "    filter_x = tf.expand_dims(tf.stack([neg, pos]), 0)  # [-1, 1]\n",
    "    filter_y = tf.stack([tf.expand_dims(pos, 0), tf.expand_dims(neg, 0)])  # [[1],[-1]]\n",
    "    strides = [1, 1, 1, 1]  # stride of (1, 1)\n",
    "    padding = 'SAME'\n",
    "\n",
    "    gen_dx = tf.abs(tf.nn.conv2d(gen_frames, filter_x, strides, padding=padding))\n",
    "    gen_dy = tf.abs(tf.nn.conv2d(gen_frames, filter_y, strides, padding=padding))\n",
    "    gt_dx = tf.abs(tf.nn.conv2d(gt_frames, filter_x, strides, padding=padding))\n",
    "    gt_dy = tf.abs(tf.nn.conv2d(gt_frames, filter_y, strides, padding=padding))\n",
    "\n",
    "    gen_grad_sum = gen_dx + gen_dy\n",
    "    gt_grad_sum = gt_dx + gt_dy\n",
    "\n",
    "    grad_diff = tf.abs(gt_grad_sum - gen_grad_sum)\n",
    "\n",
    "    batch_errors = 10 * log10(1 / ((1 / num_pixels) * tf.reduce_sum(grad_diff, [1, 2, 3])))\n",
    "    return tf.reduce_mean(batch_errors)\n",
    "\n",
    "## =================== COPIED CODE ENDS ======================\n",
    "\n",
    "def l2_loss(generated_frames, expected_frames):\n",
    "    losses = []\n",
    "    for each_scale_gen_frames, each_scale_exp_frames in zip(generated_frames, expected_frames):\n",
    "        losses.append(tf.nn.l2_loss(tf.subtract(each_scale_gen_frames, each_scale_exp_frames)))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.stack(losses))\n",
    "    return loss\n",
    "\n",
    "def gdl_loss(generated_frames, expected_frames, alpha=2):\n",
    "    \"\"\"\n",
    "    difference with side pixel and below pixel\n",
    "    \"\"\"\n",
    "    scale_losses = []\n",
    "    for i in xrange(len(generated_frames)):\n",
    "        # create filters [-1, 1] and [[1],[-1]] for diffing to the left and down respectively.\n",
    "        pos = tf.constant(np.identity(3), dtype=tf.float32)\n",
    "        neg = -1 * pos\n",
    "        filter_x = tf.expand_dims(tf.stack([neg, pos]), 0)  # [-1, 1]\n",
    "        filter_y = tf.stack([tf.expand_dims(pos, 0), tf.expand_dims(neg, 0)])  # [[1],[-1]]\n",
    "        strides = [1, 1, 1, 1]  # stride of (1, 1)\n",
    "        padding = 'SAME'\n",
    "\n",
    "        gen_dx = tf.abs(tf.nn.conv2d(generated_frames[i], filter_x, strides, padding=padding))\n",
    "        gen_dy = tf.abs(tf.nn.conv2d(generated_frames[i], filter_y, strides, padding=padding))\n",
    "        gt_dx = tf.abs(tf.nn.conv2d(expected_frames[i], filter_x, strides, padding=padding))\n",
    "        gt_dy = tf.abs(tf.nn.conv2d(expected_frames[i], filter_y, strides, padding=padding))\n",
    "\n",
    "        grad_diff_x = tf.abs(gt_dx - gen_dx)\n",
    "        grad_diff_y = tf.abs(gt_dy - gen_dy)\n",
    "\n",
    "        scale_losses.append(tf.reduce_sum((grad_diff_x ** alpha + grad_diff_y ** alpha)))\n",
    "\n",
    "    # condense into one tensor and avg\n",
    "    return tf.reduce_mean(tf.stack(scale_losses))\n",
    "\n",
    "def total_loss(generated_frames, expected_frames, lambda_gdl=1.0, lambda_l2=1.0):\n",
    "    total_loss_cal = (lambda_gdl * gdl_loss(generated_frames, expected_frames) + \n",
    "                     lambda_l2 * l2_loss(generated_frames, expected_frames))\n",
    "    return total_loss_cal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate on Directory !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = \"\"\n",
    "output_video_save_file_path = os.path.join(file_path, \"../../output/\")\n",
    "frame_eval = (4,64,64,3) # T, H, W, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter all mp4 files ! \n",
    "expected_file_names = set([])\n",
    "generated_file_names = set([])\n",
    "for root, _ , files in os.walk(output_video_save_file_path):\n",
    "    for file_name in files:\n",
    "        file_name = os.path.join(root, file_name)\n",
    "        if file_name.endswith(\"_expected_large.mp4\"):\n",
    "            expected_file_names.add(file_name.replace(\"_expected_large.mp4\",\"\"))\n",
    "        if file_name.endswith(\"_generated_large.mp4\"):\n",
    "            generated_file_names.add(file_name.replace(\"_generated_large.mp4\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_files_in_gen_exp = expected_file_names.intersection(generated_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info : Evaluating on 8 files.\n"
     ]
    }
   ],
   "source": [
    "print (\"Info : Evaluating on \"+str(len(common_files_in_gen_exp))+\" files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341.359 658.991 1000.35\n"
     ]
    }
   ],
   "source": [
    "gen_frames = []\n",
    "exp_frames = []\n",
    "for each_file in common_files_in_gen_exp:\n",
    "    gen_file = each_file + \"_generated_large.mp4\"\n",
    "    exp_file = each_file + \"_expected_large.mp4\"\n",
    "\n",
    "    gen_video_data = skvideo.io.vread(gen_file)\n",
    "    exp_video_data = skvideo.io.vread(exp_file)\n",
    "    assert gen_video_data.shape == exp_video_data.shape == frame_eval\n",
    "\n",
    "    gen_frames.append(gen_video_data)\n",
    "    exp_frames.append(exp_video_data)\n",
    "\n",
    "# get psnr_error and sharp_diff_error\n",
    "gen_frames_np = np.array(gen_frames)\n",
    "exp_frames_np = np.array(exp_frames)\n",
    "# normalize ... !\n",
    "gen_frames_np = (gen_frames_np - 127.5) / 127.5\n",
    "exp_frames_np = (exp_frames_np - 127.5) / 127.5\n",
    "B, T, H, W, C = gen_frames_np.shape\n",
    "\n",
    "gen_frames = list(np.reshape(gen_frames_np, [-1,H,W,C]))\n",
    "exp_frames = list(np.reshape(exp_frames_np,[-1,H,W,C]))\n",
    "\n",
    "# psnr_tf, sharp_diff_tf\n",
    "tf_gen = tf.placeholder(dtype=tf.float32,shape=[None,H,W,C])\n",
    "tf_exp = tf.placeholder(dtype=tf.float32,shape=[None,H,W,C])\n",
    "psnr_tf = psnr_error(tf_gen, tf_exp)\n",
    "sharp_diff_tf = sharp_diff_error(tf_gen, tf_exp)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    psnr, sharp_diff = sess.run([psnr_tf, sharp_diff_tf],feed_dict={tf_gen:gen_frames, tf_exp:exp_frames})\n",
    "\n",
    "list_of_gen_tfs = map(lambda x: tf.Variable(np.array([x]),dtype=tf.float32),gen_frames)\n",
    "list_of_exp_tfs = map(lambda x: tf.Variable(np.array([x]),dtype=tf.float32),exp_frames)\n",
    "\n",
    "l2_ls = l2_loss(list_of_gen_tfs, list_of_exp_tfs)\n",
    "gd_ls = gdl_loss(list_of_gen_tfs, list_of_exp_tfs)\n",
    "tot_ls = total_loss(list_of_gen_tfs, list_of_exp_tfs)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    l2, gd, tot = sess.run([l2_ls,gd_ls,tot_ls])\n",
    "\n",
    "print l2, gd, tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr : 13.4459\n",
      "sharp : 8.9947\n",
      "l2_ls : 341.359\n",
      "gd_ls : 658.991\n",
      "tot_ls : 1000.35\n"
     ]
    }
   ],
   "source": [
    "print \"psnr : \"+str(psnr) \n",
    "print \"sharp : \"+str(sharp_diff)\n",
    "\n",
    "print \"l2_ls : \"+str(l2)\n",
    "print \"gd_ls : \"+str(gd)\n",
    "print \"tot_ls : \"+str(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1, 2],\n",
      "       [3, 4]], dtype=int32)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
